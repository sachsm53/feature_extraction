{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "female-router",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/msachs/THINGSvision/descme_10min_frame_samecodec.mp4 fps: 23.97672318116524 total frames: 14388 total secs: 600.082\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import thingsvision.vision as vision\n",
    "\n",
    "path = '/home/msachs/THINGSvision'\n",
    "vidfilename = [elem for elem in os.listdir(path) if '.mp4' in elem][0]\n",
    "vidfile = os.path.join(path,vidfilename)\n",
    "vidcap = cv2.VideoCapture(vidfile)\n",
    "fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "duration = total_frames/fps\n",
    "\n",
    "def getFrame(sec):\n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "    hasFrames,image = vidcap.read()\n",
    "    if hasFrames:\n",
    "        resized_image = cv2.resize(image, (224, 224)) \n",
    "        countstr = \"{0:0=3d}\".format(count)\n",
    "        print(count,countstr,resized_image.shape)\n",
    "        #cv2.imwrite(\"/home/msachs/THINGSvision/images/image\"+countstr+\".jpg\", resized_image)     # save frame as JPG file\n",
    "        \n",
    "    return hasFrames\n",
    "print(vidfile, 'fps:',fps,'total frames:',int(total_frames),'total secs:',duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hourly-female",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14386 14385 (224, 224, 3) 14388.0\n"
     ]
    }
   ],
   "source": [
    "vc = cv2.VideoCapture(vidfile)\n",
    "\n",
    "c=1\n",
    "if vc.isOpened():\n",
    "    rval , frame = vc.read()\n",
    "else:\n",
    "    rval = False\n",
    "\n",
    "while rval:\n",
    "    rval, frame = vc.read()\n",
    "    if rval:\n",
    "        if c > total_frames:\n",
    "            break\n",
    "        resized_image = cv2.resize(frame, (224, 224)) \n",
    "        countstr = \"{0:0=5d}\".format(c)\n",
    "        #print(c,countstr,resized_image.shape)\n",
    "        #cv2.imwrite(str(c) + '.jpg',frame)\n",
    "        if not os.path.exists(\"/home/msachs/THINGSvision/images/image\"+countstr+\".jpg\"):\n",
    "            cv2.imwrite(\"/home/msachs/THINGSvision/images/image\"+countstr+\".jpg\", resized_image)     # save frame as JPG file\n",
    "            #print(c,countstr,resized_image.shape,\"/home/msachs/THINGSvision/images/image\"+countstr+\".jpg\")\n",
    "        #else:\n",
    "            #print(count,countstr,resized_image.shape,\"/home/msachs/THINGSvision/images/image\"+countstr+\".jpg\")\n",
    "        c = c + 1\n",
    "        #cv2.waitKey(1)\n",
    "vc.release()\n",
    "print(c,countstr,resized_image.shape,total_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-current",
   "metadata": {},
   "source": [
    "## If you want to save every 0.8 seconds (every TR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec = 0\n",
    "frameRate = 0.8 #//it will capture image in each 0.5 second\n",
    "count=1\n",
    "success = getFrame(sec)\n",
    "while success:\n",
    "    count = count + 1\n",
    "    sec = sec + frameRate\n",
    "    sec = round(sec, 2)\n",
    "    print(sec,sec*1000)\n",
    "    success = getFrame(sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "czech-cincinnati",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace=True)\n",
      "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (45): ReLU(inplace=True)\n",
      "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (48): ReLU(inplace=True)\n",
      "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (51): ReLU(inplace=True)\n",
      "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Enter module name for which you would like to extract features:\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " classifier.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = 'vgg19_bn'\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model, transforms = vision.load_model(model_name, pretrained=True, model_path=None, device=device)\n",
    "module_name = vision.show_model(model, model_name)\n",
    "\n",
    "# VGG(\n",
    "#   (features): Sequential(\n",
    "#     (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     (2): ReLU(inplace=True)\n",
    "#     (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     (5): ReLU(inplace=True)\n",
    "#     (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "#     (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     (9): ReLU(inplace=True)\n",
    "#     (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     (12): ReLU(inplace=True)\n",
    "#     (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "#     (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     (16): ReLU(inplace=True)\n",
    "#     (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     (19): ReLU(inplace=True)\n",
    "#     (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     (22): ReLU(inplace=True)\n",
    "#     (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     (25): ReLU(inplace=True)\n",
    "#     (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "#     (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     (29): ReLU(inplace=True)\n",
    "#     (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     (32): ReLU(inplace=True)\n",
    "#     (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     (35): ReLU(inplace=True)\n",
    "#     (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     (38): ReLU(inplace=True)\n",
    "#     (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "#     (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     (42): ReLU(inplace=True)\n",
    "#     (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     (45): ReLU(inplace=True)\n",
    "#     (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     (48): ReLU(inplace=True)\n",
    "#     (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "#     (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "#     (51): ReLU(inplace=True)\n",
    "#     (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "#   )\n",
    "#   (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
    "#   (classifier): Sequential(\n",
    "#     (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
    "#     (1): ReLU(inplace=True)\n",
    "#     (2): Dropout(p=0.5, inplace=False)\n",
    "#     (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "#     (4): ReLU(inplace=True)\n",
    "#     (5): Dropout(p=0.5, inplace=False)\n",
    "#     (6): Linear(in_features=4096, out_features=1000, bias=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "distinguished-diabetes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...Loading dataset into memory.\n",
      "...Creating output directory.\n",
      "...Transforming dataset into PyTorch DataLoader.\n",
      "\n",
      "...Features successfully extracted for all 14385 images in the database.\n",
      "...Features successfully saved to disk.\n",
      "\n",
      "\n",
      "Output directory did not exist. Creating directories to save targets...\n",
      "\n",
      "...Targets successfully saved to disk.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Enter part of the model for which you would like to extract features:\n",
    "\n",
    "fnames = [elem for elem in os.listdir('/home/msachs/THINGSvision/images/') if '.jpg' in elem]\n",
    "fnames.sort()\n",
    "#fnames = ['images/' + elem for elem in fnames[13:20]]\n",
    "#dl = vision.load_dl(root='/home/msachs/THINGSvision/images/', out_path='/home/msachs/THINGSvision/vgg19_bn/features.49/features', things =False, batch_size=32, transforms=transforms,file_names=fnames)\n",
    "dl = vision.load_dl(root='/home/msachs/THINGSvision/images/', out_path=f'./{model_name}/{module_name}/features', batch_size=32, transforms=transforms)\n",
    "\n",
    "features, targets = vision.extract_features(model, dl, module_name, batch_size=64, flatten_acts=True, device=device)\n",
    "vision.save_features(features, f'./{model_name}/{module_name}/features', '.npy')\n",
    "vision.save_targets(targets, f'./{model_name}/{module_name}/targets', '.npy')\n",
    "\n",
    "#For constructing visual object features, we used the Caffe implementation (Jia et al., 2014) \n",
    "#of the VGG19 deep neural network (DNN) model (Simonyan and Zisserman, 2014), \n",
    "#which was pre-trained to classify 1000 object categories (the pre-trained model \n",
    "#is available from https://github.com/BVLC/caffe/wiki/Model-Zoo). \n",
    "#The VGG19 model consisted of a total of sixteen convolutional layers and three fully connected layers. \n",
    "#To compute outputs by the VGG19 model, all frames of videos were resized to 224 Ã— 224 pixels and provided to the model. \n",
    "#The outputs from the last fully connected layer (fc8, 1000 units, before softmax operation) \n",
    "#were averaged across all frames within each video to construct a feature vector for a video.\n",
    "#Semantic\n",
    "\n",
    "#mportantly, because relationships between clinical symptoms and high-level features of the stimulus such as emotional content \n",
    "#here, emotional intensity and valence) can be confounded by lower-level features such as visual intensity \n",
    "#(Raila et al., 2015), time-courses of low-level stimulus features (brightness and loudness) \n",
    "#as well as baseline social content (faces) were also included in the fGLS regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-metallic",
   "metadata": {},
   "source": [
    "## Average the features for each TR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "encouraging-public",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished (750, 4096)\n"
     ]
    }
   ],
   "source": [
    "#first remove any row that is all zeros\n",
    "feats_rm = np.zeros((features.shape[0],features.shape[1]))\n",
    "c = 0 \n",
    "for r in range(features.shape[1]):\n",
    "    if np.mean(features[:,r]) != 0:\n",
    "        feats_rm[:,c] = features[:,r]\n",
    "        c += 1\n",
    "feats_rm = feats_rm[:,0:c]\n",
    "    \n",
    "\n",
    "#features = features_49\n",
    "tr = 0.8\n",
    "ntr = 750\n",
    "visfeats_tr = np.zeros(((int(duration/tr)),feats_rm.shape[1]))\n",
    "for e,s in enumerate(np.arange(0,int(duration),tr)):\n",
    "    start = int(s*fps)\n",
    "    end = int((s+tr)*fps)\n",
    "    #print(e,s,start,end)\n",
    "    if end > feats_rm.shape[0]:\n",
    "        end = end -1\n",
    "    visfeats_tr[e] = np.nanmean(feats_rm[start:end,:],axis = 0)\n",
    "    print(visfeats_tr[e])\n",
    "    visfeats_tr[e] = feats_rm[start:end,:].mean(axis = 0)\n",
    "    print(visfeats_tr[e])\n",
    "print('Finished',visfeats_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "conditional-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/msachs/hbn/visfeats_tr_class4.npy',visfeats_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "exempt-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check regressor for ValueError NaN, infinity or a value too large for dtype('float64').\n",
    "if np.any(np.isnan(visfeats_tr)):\n",
    "    print('Inf',np.all(np.isfinite(visfeats_tr)),'nan',np.any(np.isnan(visfeats_tr)))\n",
    "    nas = np.argwhere(np.isnan(visfeats_tr))\n",
    "    print(nas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-inspiration",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
